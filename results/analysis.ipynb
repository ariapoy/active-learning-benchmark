{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785e9600-5059-4ab8-83bc-a244a98be409",
   "metadata": {},
   "source": [
    "# Re-Benchmark of Pool-Based Active Learning for Binary Classification\n",
    "\n",
    "Reproduce all figures and tables in Re-Benchmark of Pool-Based Active Learning for Binary Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84056d5c-c6b3-416f-a954-c3919f23fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e85c5c-de86-4643-89f1-dcd90053e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_list = ['uniform', 'us', 'qbc', 'hintsvm', 'quire', 'albl', 'dwus', 'vr', 'kcenter',  # libact\n",
    "           'margin', 'graph', 'hier', 'infodiv', 'mcm',  # google\n",
    "           'eer', 'bmdr', 'spal', 'lal',  # alipy\n",
    "           'bsoDtst']\n",
    "al_list = ['us', 'qbc', 'hintsvm', 'quire', 'albl', 'dwus', 'vr', 'kcenter',  # libact\n",
    "           'margin', 'graph', 'hier', 'infodiv', 'mcm',  # google\n",
    "           'eer', 'bmdr', 'spal', 'lal',  # alipy\n",
    "          ]\n",
    "small_data_list = [\"appendicitis\", \"sonar\", \"parkinsons\", \"ex8b\", \"heart\", \"haberman\", \"ionosphere\", \"clean1\",\n",
    "             \"breast\", \"wdbc\", \"australian\", \"diabetes\", \"mammographic\", \"ex8a\", \"tic\", \"german\",\n",
    "             \"splice\", \"gcloudb\", \"gcloudub\", \"checkerboard\"]\n",
    "large_data_list = [\"spambase\", \"banana\", \"phoneme\", \"ringnorm\", \"twonorm\", \"phishing\"]\n",
    "data_list = small_data_list + large_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccda235-5803-4aa3-8a5f-e35872e93530",
   "metadata": {},
   "source": [
    "## Align results\n",
    "\n",
    "We align all results on\n",
    "- small datasets $n < 2000$ : more than 100 indicis\n",
    "- large datasets $n \\geq 2000$ : more than 10 indicis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca9a06e-74d2-4f5b-8616-bc3868902eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = os.listdir('./aubc/')\n",
    "qs_map_pos = {k: i for i, k in enumerate(qs_list)}\n",
    "table3_idx = {k: [None for _ in range(len(qs_list))] for k in data_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6da5591-484d-4dbd-9688-91f377f34e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean1-vr: 8 < 100 times\n",
      "phoneme-vr: 6 < 10 times\n",
      "checkerboard-spal: 96 < 100 times\n",
      "spambase-quire: 1 < 10 times\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    if not name.endswith('.csv'):\n",
    "        continue\n",
    "    terms = name.split('-')\n",
    "    if 'look' in name:\n",
    "        qs = terms[1] + terms[6].split('_')[-1][-4:]\n",
    "    else:\n",
    "        qs = terms[1]\n",
    "\n",
    "    data = terms[0]\n",
    "\n",
    "    res = pd.read_csv(os.path.join('./aubc/', name))\n",
    "\n",
    "    idx = res['res_expno'].unique()\n",
    "\n",
    "    if data in large_data_list:\n",
    "        if len(idx) < 10:\n",
    "            print(f'{data}-{qs}: {len(idx)} < 10 times')\n",
    "            continue\n",
    "    else:\n",
    "        if len(idx) < 100:\n",
    "            print(f'{data}-{qs}: {len(idx)} < 100 times')\n",
    "            continue\n",
    "\n",
    "    table3_idx[data][qs_map_pos[qs]] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad162d99-7933-4030-a1b0-118b2d8255e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_idx(idxArr_list):\n",
    "    res = idxArr_list[0]\n",
    "    for idxArr in idxArr_list[1:]:\n",
    "        if idxArr is None:\n",
    "            continue\n",
    "\n",
    "        res = np.intersect1d(res, idxArr)\n",
    "\n",
    "    return res\n",
    "\n",
    "aligned_idx = []\n",
    "for data in table3_idx:\n",
    "    align_idx_arr = align_idx(table3_idx[data])\n",
    "    if data in large_data_list:\n",
    "        align_idx_arr = align_idx_arr[:10]\n",
    "        assert align_idx_arr.shape[0] == 10, f'Size of {data} is not correct. {(align_idx_arr.shape[0])}'\n",
    "    else:\n",
    "        align_idx_arr = align_idx_arr[:100]\n",
    "        assert align_idx_arr.shape[0] == 100, f'Size of {data} is not correct. {(align_idx_arr.shape[0])}'\n",
    "\n",
    "    n_exp = len(align_idx_arr)\n",
    "    aligned_idx.append([data, n_exp, f'{align_idx_arr.tolist()}'])\n",
    "\n",
    "aligned_idx = pd.DataFrame(aligned_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c080068c-9b52-4d2f-8c32-01d1adc4a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_idx_dict = {}\n",
    "for data, idx in zip(aligned_idx[0], aligned_idx[2]):\n",
    "    aligned_idx_dict[data] = eval(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3f70b-c7d6-48f5-94df-4e2d884e954b",
   "metadata": {},
   "source": [
    "# Reproducing Zhan et al. Results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777670f3-7ed2-488e-8bb2-0a5b1d141b68",
   "metadata": {},
   "source": [
    "## Table. Summary Table\n",
    "\n",
    "- small datasets $n < 2000$ : only use first 100 indicis $K_{S} = 100$.\n",
    "- large datasets $n \\geq 2000$ : only use first 10 indicis $K_{L} = 10$.\n",
    "\n",
    "Calculate average (mean) and standard deviation of AUBCs by\n",
    "$$\n",
    "\\overline{\\mathrm{AUBC}}_{q, s} = \\frac{\\sum_{k=1}^{K_{\\bullet}} \\mathrm{AUBC}_{q, s, k}}{K_{\\bullet}},\n",
    "$$\n",
    "where $K_{\\bullet} \\in {K_{S}, K_{L}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9ffcd8-ae42-4580-af3f-330a1ca66f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aubc_q_s = []\n",
    "std_aubc_q_s = []\n",
    "index_duplicate = []\n",
    "for name in names:\n",
    "    if not name.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    terms = name.split('-')\n",
    "    if 'look' in name:\n",
    "        qs = terms[1] + terms[6].split('_')[-1][-4:]\n",
    "    else:\n",
    "        qs = terms[1]\n",
    "\n",
    "    data = terms[0]\n",
    "\n",
    "    if (data, qs) in index_duplicate:\n",
    "        breakpoint()\n",
    "\n",
    "    index_duplicate.append((data, qs))\n",
    "    res = pd.read_csv(os.path.join('./aubc/', name))\n",
    "\n",
    "    # aligned index\n",
    "    if aligned_idx_dict is not None:\n",
    "        res = res[res['res_expno'].isin(aligned_idx_dict[data])]\n",
    "\n",
    "    cnt_aubc = res['res_tst_score'].count()\n",
    "    if data in large_data_list:\n",
    "        if cnt_aubc < 10:\n",
    "            continue\n",
    "    else:\n",
    "        if cnt_aubc < 100:\n",
    "            continue\n",
    "\n",
    "    mean_aubc_ = res['res_tst_score'].mean()\n",
    "    std_aubc_ = res['res_tst_score'].std()\n",
    "    mean_aubc_ = round(mean_aubc_, 4)\n",
    "    std_aubc_ = round(std_aubc_, 4)\n",
    "\n",
    "    mean_aubc_q_s.append([data, qs, mean_aubc_])\n",
    "    std_aubc_q_s.append([data, qs, std_aubc_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97fde7bc-c807-4a8b-ab15-911e07366e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aubc_q_s = pd.DataFrame(mean_aubc_q_s)\n",
    "std_aubc_q_s = pd.DataFrame(std_aubc_q_s)\n",
    "\n",
    "mean_aubc_q_s.columns = ['data', 'qs', 'aubc_mean']\n",
    "std_aubc_q_s.columns = ['data', 'qs', 'aubc_std']\n",
    "\n",
    "mean_aubc_q_s = pd.pivot(mean_aubc_q_s, values='aubc_mean', index=['qs'], columns=['data'])\n",
    "std_aubc_q_s = pd.pivot(std_aubc_q_s, values='aubc_std', index=['qs'], columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e7d11d-6671-4e42-a689-8913ae1e5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aubc_q_s = mean_aubc_q_s.reindex(index=qs_list, columns=data_list)\n",
    "std_aubc_q_s = std_aubc_q_s.reindex(index=qs_list, columns=data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8607ed05-48fc-4189-b61f-a066d0b66d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str of mean and std AUBCs\n",
    "mean_aubc_q_s_str = mean_aubc_q_s.copy().astype(str)\n",
    "std_aubc_q_s_str = std_aubc_q_s.copy().astype(str)\n",
    "for d in mean_aubc_q_s.columns:\n",
    "    bst_q = mean_aubc_q_s.loc[al_list, d].nlargest(3+1).index  # as margin == infodiv in the current setting\n",
    "    if 'infodiv' not in bst_q:\n",
    "        bst_q = bst_q[:3]\n",
    "    else:\n",
    "        bst_q = bst_q.drop('infodiv')\n",
    "\n",
    "    # export to GitHub\n",
    "    mean_aubc_q_s_str.loc[bst_q[0], d] = f'{mean_aubc_q_s_str.loc[bst_q[0], d]}¹'\n",
    "    mean_aubc_q_s_str.loc[bst_q[1], d] = f'{mean_aubc_q_s_str.loc[bst_q[1], d]}²'\n",
    "    mean_aubc_q_s_str.loc[bst_q[2], d] = f'{mean_aubc_q_s_str.loc[bst_q[2], d]}³'\n",
    "\n",
    "    bst_q_std = std_aubc_q_s.loc[al_list, d].nsmallest(3+1).index\n",
    "    if 'infodiv' not in bst_q_std:\n",
    "        bst_q_std = bst_q_std[:3]\n",
    "    else:\n",
    "        bst_q_std = bst_q_std.drop('infodiv')\n",
    "\n",
    "    # export to GitHub\n",
    "    std_aubc_q_s_str.loc[bst_q_std[0], d] = f'{std_aubc_q_s_str.loc[bst_q_std[0], d]}¹'\n",
    "    std_aubc_q_s_str.loc[bst_q_std[1], d] = f'{std_aubc_q_s_str.loc[bst_q_std[1], d]}²'\n",
    "    std_aubc_q_s_str.loc[bst_q_std[2], d] = f'{std_aubc_q_s_str.loc[bst_q_std[2], d]}³'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc30b10-2cd4-4d02-8c60-47dc274c5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_aubc_q_s_str = mean_aubc_q_s_str + '(' + std_aubc_q_s_str + ')'\n",
    "mean_std_aubc_q_s_str = mean_std_aubc_q_s_str.loc[qs_list, :]\n",
    "mean_std_aubc_q_s_str.index = ['uniform', 'us', 'qbc', 'hintsvm', 'quire', 'albl', 'dwus', 'vr',\n",
    "                               'kcenter', 'margin', 'graph', 'hier', 'infodiv', 'mcm', 'eer', 'bmdr',\n",
    "                               'spal', 'lal', 'bso']\n",
    "mean_std_aubc_q_s_str = mean_std_aubc_q_s_str.T\n",
    "mean_std_aubc_q_s_str = mean_std_aubc_q_s_str.replace(to_replace='nan(nan)', value='too long (time)')\n",
    "mean_std_aubc_q_s_str.loc['checkerboard', 'spal'] = 'error'\n",
    "mean_std_aubc_q_s_str.loc['spambase', 'quire'] = 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674c8556-b694-4f88-a682-df32f7cf5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = mean_std_aubc_q_s_str.to_markdown()\n",
    "summary_table = '# Benchmark of pool-based active learning\\n\\nMean(Standard Deviation) of Uniform (Random Sampling), 17 query strategies and Beam-Search Oracle (BSO) on 26 binary datasets.\\n\\n' + summary_table\n",
    "with open('./README.md', 'w') as f:\n",
    "    f.write(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8210b5-f8b6-4a4c-b24f-749c96a0f776",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Re-Benchmark of Table 3 in Zhan et al.\n",
    "\n",
    "- RS (Uniform): $\\overline{\\mathrm{AUBC}}_{q=\\text{Uniform}, s}$.\n",
    "- BSO: $\\overline{\\mathrm{AUBC}}_{q=\\text{BSO}, s}$.\n",
    "- Avg: average of $17$ query strategies.\n",
    "$$\n",
    "\\overline{\\mathrm{AUBC}}_{s} = \\frac{\\sum_{q \\in \\text{qs}} \\overline{\\mathrm{AUBC}}_{q, s}}{17}\n",
    "$$\n",
    "where $\\text{qs} = $ {'us', 'qbc', 'hintsvm', 'quire', 'albl', 'dwus', 'vr', 'kcenter', 'margin', 'graph', 'hier', 'infodiv', 'mcm', 'eer', 'bmdr', 'spal', 'lal'}\n",
    "- BEST_val: $\\max_{q} \\overline{\\mathrm{AUBC}}_{q, s}$ and BEST_mhd: $\\arg\\max_{q} \\overline{\\mathrm{AUBC}}_{q, s}$\n",
    "- WORST_val: $\\min_{q} \\overline{\\mathrm{AUBC}}_{q, s}$ and WORST_mhd: $\\arg\\min_{q} \\overline{\\mathrm{AUBC}}_{q, s}$\n",
    "\n",
    "We also check whether mean of AUBCs in [Zhan et al., 2021] locating in\n",
    "- confidence interval with $\\alpha=0.05$ significance level.\n",
    "- confidence interval with $\\alpha=0.01$ significance level.\n",
    "\n",
    "We suppose both of experiments have the same settings.\n",
    "They will generate independent, identical distribution (i.i.d.) results.\n",
    "\n",
    "*ChatGPT*\n",
    "> If you have the mean of one sample and you want to compare it to the median of another sample, you can use the confidence interval for the mean of the first sample to see if the median of the second sample falls within the interval. This will give you an idea of whether the median of the second sample is significantly different from the mean of the first sample, but it will not be the same as the Mann-Whitney U test, which compares the medians of two independent samples.\n",
    "> This will calculate the 95% confidence interval for the mean of the first sample. You can then compare the median of the second sample to this interval to see if it falls within the interval. If the median falls within the interval, it suggests that the median is not significantly different from the mean of the first sample. If the median falls outside the interval, it suggests that the median is significantly different from the mean of the first sample.\n",
    "> Keep in mind that this approach will give you an idea of whether the median of the second sample is significantly different from the mean of the first sample, but it will not provide a formal hypothesis test or p-value like the Mann-Whitney U test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1706b60b-7b3a-4d65-b2cd-a868e8711157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add XZ2021 results\n",
    "xz2021_table3 = pd.read_csv('table3-xz2021.csv')\n",
    "# align to our code\n",
    "xz2021_table3 = xz2021_table3.set_index('XZ2021')\n",
    "xz2021_table3.columns = ['uniform', 'bsoDtst', 'Avg', 'BEST_val', 'BEST_mhd', 'WORST_val', 'WORST_mhd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b644d-54b9-481b-a6e8-265a47ee5194",
   "metadata": {},
   "source": [
    "### Table. Reporducing Failure of Uniform\n",
    "\n",
    "Check the difference between Zhan et al. and ours on Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82925c14-0118-41f8-a616-49f93060063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_uniform = pd.DataFrame()  # our results\n",
    "table3_uniform.loc[:, 'mean'] = mean_aubc_q_s.loc['uniform', :]\n",
    "table3_uniform.loc[:, 'SD'] = std_aubc_q_s.loc['uniform', :]\n",
    "table3_uniform.loc[:, '\\cite{XZ2021}'] = xz2021_table3['uniform']\n",
    "table3_uniform.loc[:, '$\\\\alpha=5\\%$'] = None\n",
    "table3_uniform.loc[:, '$\\\\alpha=1\\%$'] = None\n",
    "table3_uniform.index.name = f'{table3_uniform.index.name}($\\%$)'\n",
    "\n",
    "def tinterval_check(mean_poy, std_poy, n_poy, mean_XZ2021):\n",
    "    se = std_poy / np.sqrt(n_poy)\n",
    "    ci_95 = stats.t.interval(alpha=0.95, df=n_poy-1, loc=mean_poy, scale=se)\n",
    "    if ci_95[0] <= mean_XZ2021 <= ci_95[1]:\n",
    "        decision_95 = 0  # not significantly different with 95 confidence interval\n",
    "    else:\n",
    "        decision_95 = 1  # significantly different with 95 confidence interval\n",
    "\n",
    "    ci_99 = stats.t.interval(alpha=0.99, df=n_poy-1, loc=mean_poy, scale=se)\n",
    "    if ci_99[0] <= mean_XZ2021 <= ci_99[1]:\n",
    "        decision_99 = 0  # not significantly different with 95 confidence interval\n",
    "    else:\n",
    "        decision_99 = 1  # significantly different with 95 confidence interval\n",
    "\n",
    "    return decision_95, decision_99\n",
    "\n",
    "for data_name in table3_uniform.index:\n",
    "    if data_name in large_data_list:\n",
    "        n_samples = 10\n",
    "    else:\n",
    "        n_samples = 100\n",
    "\n",
    "    d_95, d_99 = tinterval_check(\n",
    "        table3_uniform.loc[data_name, 'mean'],\n",
    "        table3_uniform.loc[data_name, 'SD'],\n",
    "        n_samples,\n",
    "        table3_uniform.loc[data_name, '\\cite{XZ2021}']\n",
    "    )\n",
    "\n",
    "    if d_95 == 1:\n",
    "        table3_uniform.loc[data_name, '$\\\\alpha=5\\%$'] = f'Out'\n",
    "    else:\n",
    "        table3_uniform.loc[data_name, '$\\\\alpha=5\\%$'] = f'In'\n",
    "\n",
    "    if d_99 == 1:\n",
    "        table3_uniform.loc[data_name, '$\\\\alpha=1\\%$'] = f'Out'\n",
    "    else:\n",
    "        table3_uniform.loc[data_name, '$\\\\alpha=1\\%$'] = f'In'\n",
    "\n",
    "table3_uniform['mean'] = table3_uniform['mean'].apply(lambda x: f'{x:.2%}'[:-1])\n",
    "table3_uniform['SD'] = table3_uniform['SD'].apply(lambda x: f'{x:.2%}'[:-1])\n",
    "table3_uniform['\\cite{XZ2021}'] = table3_uniform['\\cite{XZ2021}'].apply(lambda x: f'{x:.1%}'[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4d9f53-d678-420d-a7ab-60a303648d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_uniform.to_latex('rsfail.tex',\n",
    "                        label='tab2:rsfail',\n",
    "                        caption='Reporducing Failure of \\\\textbf{Uniform}',\n",
    "                        escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255cc60-983d-49fd-b0ba-b61c33421c70",
   "metadata": {},
   "source": [
    "### Reporducing Failure of BSO\n",
    "\n",
    "Check the difference between Zhan et al. and ours on BSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaba72b4-a61a-4a81-9046-b3034f419263",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_bso = pd.DataFrame()\n",
    "table3_bso.loc[:, 'mean'] = mean_aubc_q_s.loc['bsoDtst', :]\n",
    "table3_bso.loc[:, 'SD'] = std_aubc_q_s.loc['bsoDtst', :]\n",
    "table3_bso.loc[:, '\\cite{XZ2021}'] = xz2021_table3['bsoDtst']\n",
    "table3_bso.loc[:, '$\\\\alpha=5\\%$'] = None\n",
    "table3_bso.loc[:, '$\\\\alpha=1\\%$'] = None\n",
    "table3_bso.index.name = f'{table3_bso.index.name}($\\%$)'\n",
    "\n",
    "n_samples = 100\n",
    "for data_name in table3_bso.index:\n",
    "    if data_name in large_data_list:\n",
    "        continue\n",
    "\n",
    "    d_95, d_99 = tinterval_check(\n",
    "        table3_bso.loc[data_name, 'mean'],\n",
    "        table3_bso.loc[data_name, 'SD'],\n",
    "        n_samples,\n",
    "        table3_bso.loc[data_name, '\\cite{XZ2021}']\n",
    "    )\n",
    "\n",
    "    if d_95 == 1:\n",
    "        table3_bso.loc[data_name, '$\\\\alpha=5\\%$'] = f'Out'\n",
    "    else:\n",
    "        table3_bso.loc[data_name, '$\\\\alpha=5\\%$'] = f'In'\n",
    "\n",
    "    if d_99 == 1:\n",
    "        table3_bso.loc[data_name, '$\\\\alpha=1\\%$'] = f'Out'\n",
    "    else:\n",
    "        table3_bso.loc[data_name, '$\\\\alpha=1\\%$'] = f'In'\n",
    "\n",
    "table3_bso['mean'] = table3_bso['mean'].apply(lambda x: f'{x:.2%}'[:-1])\n",
    "table3_bso['SD'] = table3_bso['SD'].apply(lambda x: f'{x:.2%}'[:-1])\n",
    "table3_bso['\\cite{XZ2021}'] = table3_bso['\\cite{XZ2021}'].apply(lambda x: f'{x:.1%}'[:-1])\n",
    "table3_bso = table3_bso.iloc[:-6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9a35f2-ee87-46e9-8534-2864d095545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_bso.to_latex('bsofail.tex',\n",
    "                    label='tab2:bsofail',\n",
    "                    caption='Reporducing Failure of \\\\textbf{BSO}',\n",
    "                    escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8338942-c3d3-4f82-b141-a6388be5a53b",
   "metadata": {},
   "source": [
    "### Re-Benchmarking all results of Table 3 in Zhan et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d8c29f-a055-4c49-a4ed-d8e14a40844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3 = xz2021_table3.copy().applymap(lambda x: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a48454-1a52-43a1-9c58-6fe104182c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. deal with uniform and bso\n",
    "for qs_name in ['uniform', 'bsoDtst']:\n",
    "    for data_name in table3.index:\n",
    "        if data_name in large_data_list:\n",
    "            n_samples = 10\n",
    "        else:\n",
    "            n_samples = 100\n",
    "\n",
    "        if np.isnan(xz2021_table3.loc[data_name, qs_name]):\n",
    "            continue\n",
    "            \n",
    "        d_95, d_99 = tinterval_check(\n",
    "            mean_aubc_q_s.loc[qs_name, data_name],\n",
    "            std_aubc_q_s.loc[qs_name, data_name],\n",
    "            n_samples,\n",
    "            xz2021_table3.loc[data_name, qs_name]\n",
    "        )\n",
    "\n",
    "        # update value with Poy's results\n",
    "        table3.loc[data_name, qs_name] = f'{mean_aubc_q_s.loc[qs_name, data_name]:.2%}'[:-1]\n",
    "\n",
    "        # show results\n",
    "        if d_95 == 1:\n",
    "            table3.loc[data_name, qs_name] = f'{table3.loc[data_name, qs_name]}*'\n",
    "\n",
    "        # if d_99 == 1:\n",
    "        #     report4.loc[data_name, qs_name] = f'{report4.loc[data_name, qs_name]}*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f7343ba-2715-4c23-afb4-bbdc6f73acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. deal with Avg\n",
    "table3_avg = mean_aubc_q_s.loc[al_list, :].mean().round(4)\n",
    "table3_avg_std = mean_aubc_q_s.loc[al_list, :].std().round(6)\n",
    "table3_avg_cnt = len(al_list)\n",
    "col = 'Avg'\n",
    "for data_name in table3.index:\n",
    "    if np.isnan(xz2021_table3.loc[data_name, col]):\n",
    "        continue\n",
    "\n",
    "    d_95_avg, d_99_avg = tinterval_check(\n",
    "        table3_avg.loc[data_name],\n",
    "        table3_avg_std.loc[data_name],\n",
    "        table3_avg_cnt,\n",
    "        xz2021_table3.loc[data_name, col]\n",
    "    )\n",
    "\n",
    "    # update value with Poy's results\n",
    "    table3.loc[data_name, col] = f'{table3_avg.loc[data_name]:.2%}'[:-1]\n",
    "\n",
    "    # show results\n",
    "    if d_95_avg == 1:\n",
    "        table3.loc[data_name, col] = f'{table3.loc[data_name, col]}*'\n",
    "\n",
    "    # if d_99_avg == 1:\n",
    "    #     report4.loc[data_name, col] = f'{report4.loc[data_name, col]}*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad10232-a5af-46de-bada-cdb8fda9ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. deal with BEST and WORST results\n",
    "for data_name in table3.index:\n",
    "    # update value with Poy's results\n",
    "    qs_name = mean_aubc_q_s.loc[al_list, data_name].idxmax()\n",
    "    table3.loc[data_name, 'BEST_val'] = f'{mean_aubc_q_s.loc[qs_name, data_name]:.2%}'[:-1]\n",
    "    if xz2021_table3.loc[data_name, 'BEST_mhd'] != qs_name:\n",
    "        table3.loc[data_name, 'BEST_mhd'] = f'{qs_name}*'\n",
    "    else:\n",
    "        table3.loc[data_name, 'BEST_mhd'] = qs_name\n",
    "\n",
    "for data_name in table3.index:\n",
    "    # update value with Poy's results\n",
    "    qs_name = mean_aubc_q_s.loc[al_list, data_name].idxmin()\n",
    "    table3.loc[data_name, 'WORST_val'] = f'{mean_aubc_q_s.loc[qs_name, data_name]:.2%}'[:-1]\n",
    "    if xz2021_table3.loc[data_name, 'WORST_mhd'] != qs_name:\n",
    "        table3.loc[data_name, 'WORST_mhd'] = f'{qs_name}*'\n",
    "    else:\n",
    "        table3.loc[data_name, 'WORST_mhd'] = qs_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf4e5857-4b37-47fc-8be0-57c2ec2a8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. final results\n",
    "table3_latex = table3.copy().fillna('-')\n",
    "table3_latex.index.name = 'data ($\\%$)'\n",
    "table3_latex.columns = ['RS', 'BSO', 'Avg', 'BEST\\\\_val', 'BEST\\\\_mhd', 'WORST\\\\_val', 'WORST\\\\_mhd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2acbcb-4b88-4fa9-8429-1c234f5ce083",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_latex_str = table3_latex.to_latex(\n",
    "    label='tab2:tab3',\n",
    "    caption='Re-Benchmarking all results of Table 3 in \\\\citep{XZ2021}',\n",
    "    escape=False\n",
    ")\n",
    "table3_latex_str = table3_latex_str.replace('{table}', '{table*}')  # cross 2 columns\n",
    "with open('table2-table3.tex', 'w') as f:\n",
    "    f.write(table3_latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06061152-e962-4b26-994a-38ffba3a7486",
   "metadata": {},
   "source": [
    "## Re-Benchmark of Table 4 in Zhan et al.\n",
    "\n",
    "We report the **dimension**, **scale**, **imbalance ratio** aspects as [Zhan et al., 2021].\n",
    "\n",
    "- **dimension**: Low-Dimension ($d < 50$), High-Dimensio ($d \\geq 50$)\n",
    "- **scale**: Small-Scale ($n < 1000$), Large-Scale ($n \\geq 1000$)\n",
    "- **imbalance ratio**: BALance ($r < 1.5$), IMBalance ($r \\geq 1.5$)\n",
    "\n",
    "> We present the average performance difference between the best AL/BSO and the AL method,\n",
    "> i.e., $\\delta_{i} = \\max(\\text{BSO}, a_{1}, \\dots, a_{17}) - a_{i}$,\n",
    "> where $a_{i}$ is the AUBC for the $i$-th method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0263f5b7-cac0-4da8-b35c-a23484e58a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table 2\n",
    "xz2021_table2 = pd.read_csv('table2-xz2021.csv', index_col=0)\n",
    "xz2021_table2 = xz2021_table2.drop(['fourclass'], axis=1)\n",
    "xz2021_table2.columns = ['appendicitis', 'sonar', 'parkinsons', 'ex8b', 'heart', 'haberman',\n",
    "                         'ionosphere', 'clean1', 'breast', 'wdbc', 'australian', 'diabetes',\n",
    "                         'mammographic', 'ex8a', 'tic', 'german', 'splice', 'gcloudb',\n",
    "                         'gcloudub', 'checkerboard', 'spambase', 'banana', 'phoneme', 'ringnorm',\n",
    "                         'twonorm', 'phishing']\n",
    "xz2021_table2 = xz2021_table2.T\n",
    "xz2021_table2['d'] = xz2021_table2['d'].astype(int)\n",
    "xz2021_table2['n'] = xz2021_table2['n'].astype(int)\n",
    "xz2021_table2['K'] = xz2021_table2['K'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be4a4a89-7e8e-40b9-adc1-ce23beec2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of dimension, scale and imbalance ratio\n",
    "Bin_data = xz2021_table2[xz2021_table2['K']==2].index\n",
    "Mul_data = xz2021_table2[xz2021_table2['K']>2].index\n",
    "LD_data = xz2021_table2[xz2021_table2['d']<50].index\n",
    "HD_data = xz2021_table2[xz2021_table2['d']>=50].index\n",
    "SS_data = xz2021_table2[xz2021_table2['n']<1000].index\n",
    "LS_data = xz2021_table2[xz2021_table2['n']>=1000].index\n",
    "Sy_data = ['ex8b', 'ex8a', 'gcloudb', 'gcloudub', 'checkerboard', 'banana']\n",
    "Re_data = [data for data in xz2021_table2.index.tolist() if data not in Sy_data]\n",
    "BAL_data = xz2021_table2[xz2021_table2['IR']<1.5].index\n",
    "IMB_data = xz2021_table2[xz2021_table2['IR']>=1.5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "103297ca-2d5d-4218-ba9a-d201ab5882da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>data</th>\n",
       "      <th>appendicitis</th>\n",
       "      <th>sonar</th>\n",
       "      <th>parkinsons</th>\n",
       "      <th>ex8b</th>\n",
       "      <th>heart</th>\n",
       "      <th>haberman</th>\n",
       "      <th>ionosphere</th>\n",
       "      <th>clean1</th>\n",
       "      <th>breast</th>\n",
       "      <th>wdbc</th>\n",
       "      <th>...</th>\n",
       "      <th>splice</th>\n",
       "      <th>gcloudb</th>\n",
       "      <th>gcloudub</th>\n",
       "      <th>checkerboard</th>\n",
       "      <th>spambase</th>\n",
       "      <th>banana</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>ringnorm</th>\n",
       "      <th>twonorm</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qbc</th>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hintsvm</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quire</th>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albl</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "data     appendicitis   sonar  parkinsons    ex8b   heart  haberman  \\\n",
       "qs                                                                    \n",
       "us             0.0388  0.1218      0.0317  0.0438  0.0810    0.0595   \n",
       "qbc            0.0396  0.1185      0.0379  0.0437  0.0800    0.0592   \n",
       "hintsvm        0.0447  0.1483      0.0650  0.0677  0.0891    0.0637   \n",
       "quire          0.0438  0.1365      0.0523  0.0591  0.0827    0.0652   \n",
       "albl           0.0388  0.1240      0.0367  0.0503  0.0812    0.0598   \n",
       "\n",
       "data     ionosphere  clean1  breast    wdbc  ...  splice  gcloudb  gcloudub  \\\n",
       "qs                                           ...                              \n",
       "us           0.0348  0.0890  0.0136  0.0244  ...  0.0944   0.0238    0.0193   \n",
       "qbc          0.0267  0.0878  0.0130  0.0215  ...  0.0948   0.0124    0.0154   \n",
       "hintsvm      0.0581  0.1524  0.0137  0.0283  ...  0.1319   0.0343    0.0728   \n",
       "quire        0.0530  0.1039  0.0137  0.0258  ...  0.1058   0.0315    0.0354   \n",
       "albl         0.0339  0.0953  0.0136  0.0229  ...  0.0990   0.0123    0.0301   \n",
       "\n",
       "data     checkerboard  spambase  banana  phoneme  ringnorm  twonorm  phishing  \n",
       "qs                                                                             \n",
       "us             0.0838    0.0195  0.0880   0.0148    0.0019   0.0009    0.0069  \n",
       "qbc            0.0270    0.0015  0.0022   0.0041    0.0015   0.0004    0.0019  \n",
       "hintsvm        0.0730    0.0220  0.0420   0.0276    0.0071   0.0028    0.0164  \n",
       "quire          0.0535       NaN  0.0631   0.0176       NaN      NaN       NaN  \n",
       "albl           0.0293    0.0043  0.0079   0.0112    0.0017   0.0012    0.0040  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delta\n",
    "qs_list_wo_uniform = qs_list[1:]\n",
    "table4_mean = mean_aubc_q_s.loc[qs_list_wo_uniform, :]\n",
    "table4_delta = table4_mean.max() - table4_mean\n",
    "table4_delta = table4_delta.loc[al_list, :]\n",
    "table4_delta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ad091-115a-42c1-a1d4-947f04d5269a",
   "metadata": {},
   "source": [
    "### Table. Verifying Applicability with $\\delta_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "822ff06d-7b31-422d-9b00-8e757cbd0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for table 4\n",
    "all_ = table4_delta.mean(axis=1)\n",
    "binary = table4_delta[Bin_data].mean(axis=1)\n",
    "multi = table4_delta[Mul_data].mean(axis=1)\n",
    "LD = table4_delta[LD_data].mean(axis=1)\n",
    "HD = table4_delta[HD_data].mean(axis=1)\n",
    "small = table4_delta[SS_data].mean(axis=1)\n",
    "large = table4_delta[LS_data].mean(axis=1)\n",
    "synt = table4_delta[Sy_data].mean(axis=1)\n",
    "real = table4_delta[Re_data].mean(axis=1)\n",
    "bal = table4_delta[BAL_data].mean(axis=1)\n",
    "imbal = table4_delta[IMB_data].mean(axis=1)\n",
    "table4 = pd.concat([all_, binary, multi, LD, HD, small, large, synt, real, bal, imbal], axis=1)\n",
    "table4.columns = ['All', 'B', 'M', 'LD', 'HD', 'SS', 'LS', 'R', 'S', 'BAL', 'IMB']\n",
    "table4 = table4.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1712a43-611d-4e92-9d58-e65473d953a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4_latex = table4.loc[:, ['B', 'LD', 'HD', 'SS', 'LS', 'BAL', 'IMB']]\n",
    "for col in table4_latex.columns:\n",
    "    col_nsmallest = table4_latex.nsmallest(4, col, keep='all')  # (margin == infodiv) when query batch size = 1\n",
    "    rank_qs = col_nsmallest.index\n",
    "    # export to LaTeX format\n",
    "    table4_latex.loc[:, col] = table4_latex.loc[:, col].apply(lambda x: f'{x:.2%}'[:-1])\n",
    "    # add rank of the best 3 methods\n",
    "    for rank, qs in enumerate(rank_qs):\n",
    "        if rank == 0:\n",
    "            rank = 1\n",
    "        table4_latex.loc[qs, col] = f'{table4_latex.loc[qs, col]}\\\\textsuperscript{{{rank}}}'\n",
    "\n",
    "table4_latex.index.name = f'{table4_latex.index.name}($\\%$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56ff4204-eda7-4319-a4df-e916ce9e1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4_latex.to_latex(\n",
    "    'table3-table4.tex',\n",
    "    label='tab3:tab4',\n",
    "    caption='Verifying Applicability with $\\\\delta_{i}$',\n",
    "    escape=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a60d4-265c-4074-a8fd-69928f041d35",
   "metadata": {},
   "source": [
    "## Revision of Table 2 in Zhan et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "122c2252-f8a1-4a32-9a36-0c6c0e5a1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Table 2 to LaTeX\n",
    "xz2021_table2_report = pd.read_csv('table2-xz2021Report.csv', sep='|')  # copy from the PDF\n",
    "xz2021_table2_report.columns = ['Dataset', 'Property', 'IR', '(d, n, K)']\n",
    "xz2021_table2_report['d'] = xz2021_table2_report['(d, n, K)'].str.strip().str[1:-1].str.split(',').str[0].astype(int)\n",
    "xz2021_table2_report['n'] = xz2021_table2_report['(d, n, K)'].str.strip().str[1:-1].str.split(',').str[1].astype(int)\n",
    "xz2021_table2_report['K'] = xz2021_table2_report['(d, n, K)'].str.strip().str[1:-1].str.split(',').str[2].astype(int)\n",
    "xz2021_table2_report = xz2021_table2_report.drop('(d, n, K)', axis=1)\n",
    "xz2021_table2_report = xz2021_table2_report.set_index('Dataset')\n",
    "xz2021_table2_report.index = ['appendicitis', 'sonar', 'iris', 'wine', 'parkinson', 'ex8b',\n",
    "       'seeds', 'glass', 'thyroid', 'heart', 'haberman', 'ionosphere',\n",
    "       'clean1', 'breast', 'wdbc', 'r15', 'australian',\n",
    "       'diabetes', 'mammographic', 'ex8a', 'vehicle',\n",
    "       'tic', 'german', 'splice',\n",
    "       'gcloudb', 'gcloudub',\n",
    "       'checkerboard', 'phishing', 'd31', 'spambase',\n",
    "       'banana', 'phoneme', 'texture', 'ringnorm', 'twonorm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f2049f7-6b55-4644-8f7e-f25c229d6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = pd.merge(\n",
    "    xz2021_table2, xz2021_table2_report,\n",
    "    how='left', left_index=True, right_index=True,\n",
    "    suffixes=('', '_xz2021')\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abbc4e26-cda4-492b-9fb5-1e840f7488fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2_latex = table2.copy()\n",
    "table2_latex['d_str'] = table2_latex.apply(lambda x: str(int(x['d_xz2021'])) + '$\\\\rightarrow$' + str(x['d'])\n",
    "                                       if x['d'] != x['d_xz2021']\n",
    "                                       else str(int(x['d'])), axis=1\n",
    "                                      )\n",
    "table2_latex['IR_str'] = table2_latex.apply(lambda x: str(int(x['IR_xz2021'])) + '$\\\\rightarrow$' + str(x['IR'])\n",
    "                                       if x['IR'] != x['IR_xz2021']\n",
    "                                       else str(int(x['IR'])), axis=1\n",
    "                                      )\n",
    "table2_latex['n_str'] = table2_latex.apply(lambda x: str(int(x['n_xz2021'])) + '$\\\\rightarrow$' + str(x['n'])\n",
    "                                       if x['n'] != x['n_xz2021']\n",
    "                                       else str(int(x['n'])), axis=1\n",
    "                                      )\n",
    "table2_latex['K_str'] = table2_latex.apply(lambda x: str(int(x['K_xz2021'])) + '$\\\\rightarrow$' + str(x['K'])\n",
    "                                       if x['K'] != x['K_xz2021']\n",
    "                                       else str(int(x['K'])), axis=1\n",
    "                                      )\n",
    "\n",
    "table2_latex = table2_latex[['Property', 'IR_str', 'd_str', 'n_str', 'K_str']]\n",
    "table2_latex.columns = ['Property', '$r$', '$d$', '$n$', '$K$']\n",
    "table2_latex = table2_latex[table2_latex.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be5bf0d8-ddb6-48b3-a50c-8c71cae47980",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2_latex.to_latex(\n",
    "    'table2-table2.tex',\n",
    "    label='tab2:tab2',\n",
    "    caption='Revision of Table 2 in \\\\citep{XZ2021}',\n",
    "    escape=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e7b12-45e1-4d44-b74f-4f6b38e4e98d",
   "metadata": {},
   "source": [
    "# Proposed Analysis Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494376a1-005d-4824-8482-d2ff61c8d191",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figure. The learning curves of query strategies on Heart\n",
    "\n",
    "Plot learning curves of several query strategies on *Heart* dataset.\n",
    "- Input. `detail/*.csv` with format \"seed|round|accuracy|time of training|time of querying\".\n",
    "- Align the seed of query strategies.\n",
    "- Calculate mean and standard deviation (SD) of accuracy.\n",
    "- Plot mean, upper bound (mean + SD) and lower bound (mean - SD) of accuracy (y-axis) along number of labels (x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "974b1533-0a05-4ec1-a359-8e5c1afe26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change data and (lc_qs, colors) by yourself.\n",
    "data = 'heart'\n",
    "lc_qs = [\n",
    "    'uniform-zhan-google-zhan',  # gray\n",
    "    'us-zhan-us-zhan',           # r\n",
    "    'qbc-zhan-qbc-zhan',         # r\n",
    "    'albl-zhan-albl-zhan',       # r\n",
    "    'kcenter-zhan-libact-zhan',  # g\n",
    "    'margin-zhan-google-zhan',   # r\n",
    "    'mcm-zhan-google-zhan',      # b\n",
    "    'eer-zhan-eer-zhan',       # r\n",
    "    'spal-zhan-alipy-zhan',      # b\n",
    "    'lal-zhan-alipy-zhan',       # b\n",
    "]\n",
    "linestys = ['-']\n",
    "colors = ['gray', 'gold', 'orange', 'deeppink',\n",
    "          'green', 'red', 'blue',\n",
    "          'brown', 'steelblue', 'violet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3365c910-4638-4a8a-aa52-b118932816c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_detail_csv(name, align=None):\n",
    "    path = Path(name)\n",
    "    if not path.is_file():\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(name, header=None, sep='|')\n",
    "    df = df.loc[:, [0, 1, 2]]  # 0: seed, 1: round, 2: test accuracy\n",
    "    if align:\n",
    "        df = df[df[0].isin(align)]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def clean_detail_df(df):\n",
    "    try:\n",
    "        if df[2].dtype == float:\n",
    "            pass\n",
    "        else:\n",
    "            df = df[df[2].str.contains('lr')==False]\n",
    "            df[2] = df[2].astype(float)\n",
    "    except:\n",
    "        df = None\n",
    "\n",
    "    return df\n",
    "\n",
    "learning_curves = []\n",
    "skip_qs_idx = []\n",
    "for i, exp in enumerate(lc_qs):\n",
    "    res_detail = read_detail_csv(f'detail/{data}-{exp}-zhan-RS_noFix_scale-detail.csv', align=aligned_idx_dict[data])\n",
    "    clean_detail = clean_detail_df(res_detail)\n",
    "    if clean_detail is None:\n",
    "        print(f'{name} fail')\n",
    "        import pdb; pdb.set_trace()\n",
    "        skip_qs_idx.append(i)                                                                                                                                            \n",
    "        continue\n",
    "\n",
    "    if clean_detail.shape[1] > 5:\n",
    "        clean_detail = clean_detail_df(clean_detail)\n",
    "        clean_detail.columns = range(5)\n",
    "\n",
    "    res_lc = clean_detail.groupby(1).agg({2: ['mean', 'std', 'count']})\n",
    "    res_lc.columns = ['avg', 'std', 'cnt']\n",
    "    res_lc.index.name = None\n",
    "    res_lc.index = res_lc.index.astype(int)\n",
    "    learning_curves.append(res_lc)\n",
    "\n",
    "lc_qs = [x for i, x in enumerate(lc_qs) if i not in skip_qs_idx]\n",
    "colors = [x for i, x in enumerate(colors) if i not in skip_qs_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5546cd48-8140-424f-855d-b59e9b413a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = pd.concat([df['avg'] for df in learning_curves], axis=1)\n",
    "stds = pd.concat([df['std'] for df in learning_curves], axis=1)\n",
    "avgs.columns = lc_qs\n",
    "stds.columns = lc_qs\n",
    "upper = avgs + stds\n",
    "lower = avgs - stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "312dd9aa-4ae1-49cd-b30a-f0603a3fd04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "for i, name in enumerate(lc_qs):\n",
    "    if name not in ('uniform-zhan-google-zhan', 'margin-zhan-google-zhan', 'mcm-zhan-google-zhan'):\n",
    "        continue\n",
    "\n",
    "    cur_line = avgs[name].dropna()\n",
    "    plt.plot(cur_line.index, cur_line, linestyle=linestys[0], color=colors[i], label=name)\n",
    "    cur_upper = upper[name].dropna()\n",
    "    cur_lower = lower[name].dropna()\n",
    "    plt.fill_between(cur_lower.index, cur_lower, cur_upper, facecolor=colors[i], alpha=0.1)\n",
    "\n",
    "plt.xlabel(\"# of labeled samples\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.legend(ncol=2, loc='best', bbox_to_anchor=(0.5, 0., 0.5, 0.5))\n",
    "export_name = f\"lc-{data}.png\"\n",
    "plt.savefig(export_name, bbox_inches='tight')                                                                                                                       \n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa716-b7de-4166-999f-766698d2553c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figure. Difference AUBC between Margin and Uniform on *Heart*\n",
    "\n",
    "Plot learning curves of several query strategies on *Heart* dataset.\n",
    "- Input. `aubc/*.csv` with format \"res_expno,res_lbl_score,res_tst_score\".\n",
    "- Align the seed of query strategies.\n",
    "- Calculate difference AUBC between {qs} and Uniform.\n",
    "- Plot difference AUBC (y-axis) along index of seeds (x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9fc4fdb-61fa-4e33-abd9-12e29d50466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'heart'\n",
    "qs = [\n",
    "    'uniform-zhan-google-zhan',  # Uniform\n",
    "    'margin-zhan-google-zhan',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1adaf6a-6d9c-41b9-b890-7749e99b0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aubc_csv(name, align=None):\n",
    "    path = Path(name)\n",
    "    if not path.is_file():\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(name)\n",
    "    if align:\n",
    "        df = df[df['res_expno'].isin(align)]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.set_index('res_expno')\n",
    "    df = df.loc[:, 'res_tst_score']\n",
    "    if df.shape[0] not in (100, 10):\n",
    "        print(f'{name} Error #exps {df.shape[0]}!')\n",
    "        df = None\n",
    "\n",
    "    return df\n",
    "\n",
    "aubc_qs_data_seed = []\n",
    "for i, exp in enumerate(qs):\n",
    "    res_aubc = read_aubc_csv(f'aubc/{data}-{exp}-zhan-RS_noFix_scale-aubc.csv', align=aligned_idx_dict[data])\n",
    "    if res_aubc is None:\n",
    "        print(f'{exp} fail')\n",
    "        import pdb; pdb.set_trace()\n",
    "        skip_qs_idx.append(i)                                                                                                                                            \n",
    "        continue\n",
    "\n",
    "    aubc_qs_data_seed.append(res_aubc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1af6c093-fe89-49c5-8523-0e860cbbd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_qs_data_seed = (aubc_qs_data_seed[1] - aubc_qs_data_seed[0]).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97349fd9-c01a-45bf-b608-c2bae98e50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_qs_data_seed_mean = tau_qs_data_seed['res_tst_score'].mean()\n",
    "tau_qs_data_seed_std = tau_qs_data_seed['res_tst_score'].std()\n",
    "tau_qs_data_seed_cnt = tau_qs_data_seed['res_tst_score'].count()\n",
    "tau_qs_data_seed_sem = tau_qs_data_seed_std/np.sqrt(tau_qs_data_seed_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8dfcbc14-a684-4f94-b470-6d6924bcb283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "tau_qs_data_seed['res_tst_score'].plot(marker='.', linestyle='--', c='tab:purple', label='margin', alpha=0.5, ms=10)\n",
    "plt.xlabel('Index of Seed')\n",
    "plt.ylabel('Difference AUBC between Margin from Uniform')\n",
    "plt.axhline(y=0, linestyle='--', color='black')\n",
    "plt.axhline(y=tau_qs_data_seed_mean, color='tab:purple', label='mean difference AUBC')\n",
    "plt.gca().add_patch(plt.Rectangle((0, tau_qs_data_seed_mean-tau_qs_data_seed_sem), 100, 2*tau_qs_data_seed_sem, facecolor=\"orange\", alpha=0.5, label='95% C.I.'))\n",
    "plt.legend()\n",
    "plt.savefig('scat-improve.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a5a1e-e028-402d-a7e1-3173351b6626",
   "metadata": {},
   "source": [
    "## Table. (Online) $\\bar{\\tau}_{q, s}$ and $\\text{SD}(\\tau)_{q, s}$\n",
    "\n",
    "Estimate the mean and SD of $\\tau_{q, s}$ by seeds and illustrate $95\\%$ confidence interval (C.I.).\n",
    "\n",
    "- Input. `aubc/*.csv` with format \"res_expno,res_lbl_score,res_tst_score\".\n",
    "- Align the seed of query strategies.\n",
    "- Calculate difference AUBC between {qs} and Uniform.\n",
    "- Calculate mean and SD of difference AUBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6fe9a55-63a7-4e71-942b-a3ef445a4166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubc/spambase-quire-zhan-libact-zhan-zhan-RS_noFix_scale-aubc.csv Error #exps 1!\n",
      "aubc/clean1-vr-zhan-vr-zhan-zhan-RS_noFix_scale-aubc.csv Error #exps 8!\n",
      "aubc/phoneme-vr-zhan-vr-zhan-zhan-RS_noFix_scale-aubc.csv Error #exps 6!\n",
      "aubc/checkerboard-spal-zhan-alipy-zhan-zhan-RS_noFix_scale-aubc.csv Error #exps 66!\n"
     ]
    }
   ],
   "source": [
    "qs_file_list = ['uniform-zhan-google-zhan', 'us-zhan-us-zhan', 'qbc-zhan-qbc-zhan', 'hintsvm-zhan-libact-zhan', 'quire-zhan-libact-zhan',\n",
    "                'albl-zhan-albl-zhan', 'dwus-zhan-libact-zhan', 'vr-zhan-vr-zhan', 'kcenter-zhan-libact-zhan',  # libact\n",
    "                'margin-zhan-google-zhan', 'graph-zhan-google-zhan', 'hier-zhan-google-zhan', 'infodiv-zhan-google-zhan', 'mcm-zhan-google-zhan',  # google\n",
    "                'eer-zhan-eer-zhan', 'bmdr-zhan-alipy-zhan', 'spal-zhan-alipy-zhan', 'lal-zhan-alipy-zhan',  # alipy\n",
    "                'bso-zhan-bso-zhan']\n",
    "\n",
    "aubc_qs_data_seed = {}\n",
    "aubc_data_skipQS = {}\n",
    "for qs in qs_file_list:\n",
    "    for data in data_list:\n",
    "        if 'bso' not in qs:\n",
    "            res_aubc = read_aubc_csv(f'aubc/{data}-{qs}-zhan-RS_noFix_scale-aubc.csv', align=aligned_idx_dict[data])\n",
    "        else:\n",
    "            res_aubc = read_aubc_csv(f'aubc/{data}-{qs}-zhan-RS_noFix_scale_lookDtst-aubc.csv', align=aligned_idx_dict[data])\n",
    "\n",
    "        if aubc_qs_data_seed.get(data):\n",
    "            aubc_qs_data_seed[data].update({qs: res_aubc})\n",
    "        else:\n",
    "            aubc_qs_data_seed[data] = {qs: res_aubc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f35a9a0-ce26-49a6-a387-fce0828d2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_qs_data_seed = {}\n",
    "for data in aubc_qs_data_seed:\n",
    "    aubc_ = pd.DataFrame(aubc_qs_data_seed[data])\n",
    "    aubc_.columns = qs_list\n",
    "    tau_ = aubc_.sub(aubc_['uniform'], axis=0)\n",
    "    tau_qs_data_seed[data] = tau_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "540ffcd1-5ced-4ca4-8dbf-5e3f8e2747d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_qs_data_mean = {data: tau_qs_data_seed[data].mean() for data in tau_qs_data_seed}\n",
    "tau_qs_data_mean = pd.DataFrame(tau_qs_data_mean)\n",
    "tau_qs_data_mean = tau_qs_data_mean.loc[al_list, :]\n",
    "tau_qs_data_mean = tau_qs_data_mean.loc[:, data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b71ef41a-31ed-4d6c-b0cd-431f0d79a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_qs_data_std = {data: tau_qs_data_seed[data].std() for data in tau_qs_data_seed}\n",
    "tau_qs_data_std = pd.DataFrame(tau_qs_data_std)\n",
    "tau_qs_data_std = tau_qs_data_std.loc[al_list, :]\n",
    "tau_qs_data_std = tau_qs_data_std.loc[:, data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6a6d53d-5246-4d36-8dec-269f1a000b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lu/Documents/active-learning-benchmark/mlrc21-env/lib/python3.10/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "not_enough_exps = []  # normaltest\n",
    "sim_performance_datasets = []  # bartlett\n",
    "tau_data_qs = tau_qs_data_mean.copy().applymap(lambda x: None)\n",
    "tau_data_qs_cnt = tau_data_qs.copy()\n",
    "for data in aubc_qs_data_seed:\n",
    "    aubc_ = pd.DataFrame(aubc_qs_data_seed[data])\n",
    "    aubc_.columns = qs_list\n",
    "    aubc_ = aubc_.dropna(axis=1)\n",
    "    aubc_uniform_ = aubc_['uniform']\n",
    "    aubc_qss_ = aubc_.drop(['uniform'], axis=1)\n",
    "    if 'bsoDtst' in aubc_qss_:\n",
    "        aubc_qss_ = aubc_qss_.drop(['bsoDtst'], axis=1)\n",
    "\n",
    "    # hypothesis test\n",
    "    # check for normality of each qs (column)\n",
    "    # https://www.allendowney.com/blog/2023/01/28/never-test-for-normality/\n",
    "    # Results of normality test: not enough of experiments\n",
    "    alpha = 1e-3\n",
    "    cur_data_qss = []\n",
    "    for qs in aubc_qss_.columns:\n",
    "        _, p_val = stats.normaltest(aubc_qss_[qs].values)\n",
    "        if p_val < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "            not_enough_exps.append((qs, data))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        cur_data_qss.append(aubc_qss_[qs])\n",
    "        # mean of difference between (Uniform, QS)\n",
    "        cur_tau = aubc_qss_[qs].sub(aubc_uniform_, axis=0).mean().round(4)\n",
    "        tau_data_qs.loc[qs, data] = cur_tau\n",
    "        tau_data_qs_cnt.loc[qs, data] = cur_tau  # Use for judge = or < uniform\n",
    "\n",
    "    # check for equal variances of all qs (data)\n",
    "    _, p_val = stats.bartlett(*cur_data_qss)\n",
    "    if p_val < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        sim_performance_datasets.append(data)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # paired t-test of each qs (column)\n",
    "    for qs in aubc_qss_.columns:\n",
    "        _, p_value = stats.ttest_rel(aubc_uniform_, aubc_qss_[qs], alternative='less')\n",
    "        alpha_95 = 0.05\n",
    "        alpha_99 = 0.01\n",
    "\n",
    "        # update table with decision\n",
    "        if p_value < alpha_95:  # > uniform with 95 CI\n",
    "            tau_data_qs.loc[qs, data] = f'{tau_data_qs.loc[qs, data]}*'\n",
    "            tau_data_qs_cnt.loc[qs, data] = 1\n",
    "        if p_value < alpha_99:  #  # > uniform with 99 CI\n",
    "            tau_data_qs.loc[qs, data] = f'{tau_data_qs.loc[qs, data]}*'\n",
    "            tau_data_qs_cnt.loc[qs, data] = 2\n",
    "        else:\n",
    "            if tau_data_qs_cnt.loc[qs, data] < 0:  # < uniform\n",
    "                tau_data_qs_cnt.loc[qs, data] = -1\n",
    "            else:  # = uniform\n",
    "                tau_data_qs_cnt.loc[qs, data] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a13739e9-9307-4309-a55f-10aa7ff4e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export not_enough_exps & sim_performance_datasets\n",
    "tau_data_qs_markdown = tau_data_qs.copy()\n",
    "for trial in not_enough_exps:\n",
    "    qs, data = trial\n",
    "    tau_data_qs_markdown.loc[qs, data] = f'{tau_data_qs_markdown.loc[qs, data]}' + '⚠️'\n",
    "\n",
    "new_columns = []\n",
    "for i, data in enumerate(tau_data_qs_markdown.columns):\n",
    "    if data in sim_performance_datasets:\n",
    "        new_columns.append(f'{tau_data_qs_markdown.columns[i]}' + '🤔')\n",
    "    else:\n",
    "        new_columns.append(f'{tau_data_qs_markdown.columns[i]}')\n",
    "\n",
    "tau_data_qs_markdown.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbd9a469-28a5-4d2c-8961-cab050c0d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_data_qs_description = '''# Usefulness of query strategies\\n\\nMean difference of the query strategy from Uniform\\n`*\\' and `**\\' mean reject pair $t$-test with significance level $0.05$ and $0.01$ respectively.\\n\n",
    "- The `⚠️\\' means not enough number of repeated experiments.\n",
    "- The `🤔\\' means hard to differentiate the performance of different query strategies.\\n\\n'''\n",
    "\n",
    "with open('./README.md', 'a') as f:\n",
    "    '# Benchmark of pool-based active learning\\n\\nMean(Standard Deviation) of Uniform (Random Sampling), 17 query strategies and Beam-Search Oracle (BSO) on 26 binary datasets.\\n\\n'\n",
    "    f.write(tau_data_qs_description)\n",
    "    f.write(tau_data_qs_markdown.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a4f67-1c50-494d-924b-fd877a6acf99",
   "metadata": {},
   "source": [
    "## Figure. Number of significant improvement of Query Strategy from Uniform\n",
    "\n",
    "Count the number of (query strategy, *dataset*) that mean AUBC difference is greater than $0$ with $\\alpha=5\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "630c6718-19b4-4ac5-8a20-c1d650dab90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_data_qs_cnt_dataview = tau_data_qs_cnt.gt(0).sum()\n",
    "tau_data_qs_cnt_qsview = tau_data_qs_cnt.gt(0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3951fad6-7db7-451a-a15f-a5aa0e20cfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax_data, ax_qs) = plt.subplots(nrows=1, ncols=2, figsize=(12,8))\n",
    "tau_data_qs_cnt_dataview.plot(kind='barh', ax=ax_data)\n",
    "tau_data_qs_cnt_qsview.plot(kind='barh', ax=ax_qs)\n",
    "ax_data.set_title('Dataset aspect')\n",
    "ax_data.set_ylabel('')\n",
    "ax_data.invert_yaxis()\n",
    "ax_data.set_xlim(0, 17)\n",
    "ax_qs.set_title('Query strategy aspect')\n",
    "ax_qs.set_ylabel('')\n",
    "ax_qs.set_xlim(0, 26)\n",
    "ax_qs.invert_yaxis()\n",
    "fig.savefig('n_QSgtRS.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2bcd9-adb8-4129-b95a-78463289bbb5",
   "metadata": {},
   "source": [
    "## Figure. Improvement of Query Strategies over Uniform on *Heart*\n",
    "\n",
    "Compare the $\\tau_{q, s, k}$, where \n",
    "- $q \\in$ {US, QBC, ALBL, Margin (InfoDiv), MCM, LAL, KCenter, EER, SPAL}.\n",
    "- $s = $ *Heart*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf33f23d-3ebd-42a6-bb9c-d0c7010565f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_al = ['us', 'qbc', 'albl', 'margin', 'mcm', 'lal', 'kcenter', 'eer', 'spal']\n",
    "data = 'heart'\n",
    "useful_al_mcolor = {\n",
    "    'us': 'salmon',\n",
    "    'qbc': 'tab:orange',\n",
    "    'albl': 'tab:pink',\n",
    "    'kcenter': 'tab:green',\n",
    "    'margin': 'tab:red',\n",
    "    'mcm': 'tab:blue',\n",
    "    'eer': 'brown',\n",
    "    'spal': 'tab:cyan',\n",
    "    'lal': 'magenta',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef5a3122-c447-4d38-b435-2a7f29c6b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_useful_heart_seed = tau_qs_data_seed['heart'].loc[:, useful_al]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1ebba3b-f353-401d-9a62-ba157132f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "tau_useful_heart_seed.plot(marker='.', linestyle='--', alpha=0.5, ms=10)\n",
    "plt.xlabel('Index of Seed')\n",
    "plt.ylabel('Difference AUBC between QS from Uniform')\n",
    "plt.axhline(y=0, linestyle='--', color='black')\n",
    "plt.legend()\n",
    "plt.savefig('scat-rank.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13acdd-46f4-429b-b851-c70de6638a19",
   "metadata": {},
   "source": [
    "## Table. Average Ranking of the Query Startegy\n",
    "\n",
    "Apply Friedman test with $\\alpha=0.05$ on $\\bar{\\tau}_{q, s}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "055a7308-2a1f-4d3d-b559-738681cf2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_tau_qs_data = {}\n",
    "rank_tau_qs_data = {}\n",
    "for data in tau_qs_data_seed:\n",
    "    cur_data = tau_qs_data_seed[data]\n",
    "    cur_data = cur_data.loc[:, useful_al]\n",
    "    cur_data = cur_data.dropna(axis=1, how='all')\n",
    "    cur_data = cur_data.dropna()\n",
    "    avg_rank_tau_qs_data[data] = cur_data.rank(axis=1, ascending=False).mean()\n",
    "    rank_tau_qs_data[data] = cur_data.rank(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb655d31-2018-47d6-aa03-ea5818706ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: appendicitis p-value is significant\n",
      "1: sonar p-value is significant\n",
      "2: parkinsons p-value is significant\n",
      "3: ex8b p-value is significant\n",
      "4: heart p-value is significant\n",
      "5: haberman p-value is significant\n",
      "6: ionosphere p-value is significant\n",
      "7: clean1 p-value is significant\n",
      "8: breast p-value is significant\n",
      "9: wdbc p-value is significant\n",
      "10: australian p-value is significant\n",
      "11: diabetes p-value is significant\n",
      "12: mammographic p-value is significant\n",
      "13: ex8a p-value is significant\n",
      "14: tic p-value is significant\n",
      "15: german p-value is significant\n",
      "16: splice p-value is significant\n",
      "17: gcloudb p-value is significant\n",
      "18: gcloudub p-value is significant\n",
      "19: checkerboard p-value is significant\n",
      "20: spambase p-value is significant\n",
      "21: banana p-value is significant\n",
      "22: phoneme p-value is significant\n",
      "23: ringnorm p-value is significant\n",
      "24: twonorm p-value is significant\n",
      "25: phishing p-value is significant\n"
     ]
    }
   ],
   "source": [
    "# Friedman test\n",
    "for i, data in enumerate(rank_tau_qs_data):\n",
    "    # Perform the Friedman test\n",
    "    friedman_test, p_value = stats.friedmanchisquare(*[rank_tau_qs_data[data].values[:, i] for i in range(rank_tau_qs_data[data].values.shape[1])])\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f'{i}: {data} p-value is significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94bdbd1e-032a-426c-b4b6-ceb151670b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appendicitis</th>\n",
       "      <th>sonar</th>\n",
       "      <th>parkinsons</th>\n",
       "      <th>ex8b</th>\n",
       "      <th>heart</th>\n",
       "      <th>haberman</th>\n",
       "      <th>ionosphere</th>\n",
       "      <th>clean1</th>\n",
       "      <th>breast</th>\n",
       "      <th>wdbc</th>\n",
       "      <th>...</th>\n",
       "      <th>splice</th>\n",
       "      <th>gcloudb</th>\n",
       "      <th>gcloudub</th>\n",
       "      <th>checkerboard</th>\n",
       "      <th>spambase</th>\n",
       "      <th>banana</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>ringnorm</th>\n",
       "      <th>twonorm</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>albl</th>\n",
       "      <td>4.855</td>\n",
       "      <td>5.360</td>\n",
       "      <td>5.380</td>\n",
       "      <td>6.400</td>\n",
       "      <td>5.255</td>\n",
       "      <td>5.050</td>\n",
       "      <td>6.325</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.845</td>\n",
       "      <td>5.795</td>\n",
       "      <td>...</td>\n",
       "      <td>5.22</td>\n",
       "      <td>3.980</td>\n",
       "      <td>6.420</td>\n",
       "      <td>5.95</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eer</th>\n",
       "      <td>4.880</td>\n",
       "      <td>6.200</td>\n",
       "      <td>5.315</td>\n",
       "      <td>4.970</td>\n",
       "      <td>6.080</td>\n",
       "      <td>4.490</td>\n",
       "      <td>5.080</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.950</td>\n",
       "      <td>4.730</td>\n",
       "      <td>...</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.575</td>\n",
       "      <td>6.285</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kcenter</th>\n",
       "      <td>5.480</td>\n",
       "      <td>7.195</td>\n",
       "      <td>7.690</td>\n",
       "      <td>5.665</td>\n",
       "      <td>5.565</td>\n",
       "      <td>5.945</td>\n",
       "      <td>7.680</td>\n",
       "      <td>8.32</td>\n",
       "      <td>5.045</td>\n",
       "      <td>6.875</td>\n",
       "      <td>...</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.630</td>\n",
       "      <td>8.680</td>\n",
       "      <td>1.88</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lal</th>\n",
       "      <td>4.830</td>\n",
       "      <td>4.390</td>\n",
       "      <td>5.165</td>\n",
       "      <td>4.825</td>\n",
       "      <td>4.890</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.375</td>\n",
       "      <td>4.16</td>\n",
       "      <td>5.670</td>\n",
       "      <td>5.475</td>\n",
       "      <td>...</td>\n",
       "      <td>6.32</td>\n",
       "      <td>5.765</td>\n",
       "      <td>4.770</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.70</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin</th>\n",
       "      <td>4.595</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.690</td>\n",
       "      <td>3.285</td>\n",
       "      <td>3.765</td>\n",
       "      <td>5.205</td>\n",
       "      <td>2.695</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.225</td>\n",
       "      <td>2.030</td>\n",
       "      <td>...</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.735</td>\n",
       "      <td>1.440</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcm</th>\n",
       "      <td>4.515</td>\n",
       "      <td>3.160</td>\n",
       "      <td>2.770</td>\n",
       "      <td>3.565</td>\n",
       "      <td>4.035</td>\n",
       "      <td>5.170</td>\n",
       "      <td>2.980</td>\n",
       "      <td>2.56</td>\n",
       "      <td>4.245</td>\n",
       "      <td>2.450</td>\n",
       "      <td>...</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.065</td>\n",
       "      <td>1.930</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qbc</th>\n",
       "      <td>5.215</td>\n",
       "      <td>4.465</td>\n",
       "      <td>5.635</td>\n",
       "      <td>4.840</td>\n",
       "      <td>4.770</td>\n",
       "      <td>4.750</td>\n",
       "      <td>3.755</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.300</td>\n",
       "      <td>4.470</td>\n",
       "      <td>...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.980</td>\n",
       "      <td>3.070</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spal</th>\n",
       "      <td>5.730</td>\n",
       "      <td>6.770</td>\n",
       "      <td>6.980</td>\n",
       "      <td>6.735</td>\n",
       "      <td>5.620</td>\n",
       "      <td>4.870</td>\n",
       "      <td>5.750</td>\n",
       "      <td>7.93</td>\n",
       "      <td>4.700</td>\n",
       "      <td>7.470</td>\n",
       "      <td>...</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.620</td>\n",
       "      <td>7.910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>4.900</td>\n",
       "      <td>4.850</td>\n",
       "      <td>3.375</td>\n",
       "      <td>4.715</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.020</td>\n",
       "      <td>6.360</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.020</td>\n",
       "      <td>5.705</td>\n",
       "      <td>...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>6.650</td>\n",
       "      <td>4.495</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.55</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appendicitis  sonar  parkinsons   ex8b  heart  haberman  ionosphere  \\\n",
       "albl            4.855  5.360       5.380  6.400  5.255     5.050       6.325   \n",
       "eer             4.880  6.200       5.315  4.970  6.080     4.490       5.080   \n",
       "kcenter         5.480  7.195       7.690  5.665  5.565     5.945       7.680   \n",
       "lal             4.830  4.390       5.165  4.825  4.890     4.500       4.375   \n",
       "margin          4.595  2.610       2.690  3.285  3.765     5.205       2.695   \n",
       "mcm             4.515  3.160       2.770  3.565  4.035     5.170       2.980   \n",
       "qbc             5.215  4.465       5.635  4.840  4.770     4.750       3.755   \n",
       "spal            5.730  6.770       6.980  6.735  5.620     4.870       5.750   \n",
       "us              4.900  4.850       3.375  4.715  5.020     5.020       6.360   \n",
       "\n",
       "         clean1  breast   wdbc  ...  splice  gcloudb  gcloudub  checkerboard  \\\n",
       "albl       5.47   5.845  5.795  ...    5.22    3.980     6.420          5.95   \n",
       "eer        6.07   4.950  4.730  ...    5.74    5.575     6.285          3.16   \n",
       "kcenter    8.32   5.045  6.875  ...    8.86    6.630     8.680          1.88   \n",
       "lal        4.16   5.670  5.475  ...    6.32    5.765     4.770          6.21   \n",
       "margin     2.39   4.225  2.030  ...    2.09    2.735     1.440          2.51   \n",
       "mcm        2.56   4.245  2.450  ...    2.03    3.065     1.930          2.79   \n",
       "qbc        3.90   4.300  4.470  ...    3.98    3.980     3.070          5.55   \n",
       "spal       7.93   4.700  7.470  ...    6.85    6.620     7.910           NaN   \n",
       "us         4.20   6.020  5.705  ...    3.91    6.650     4.495          7.95   \n",
       "\n",
       "         spambase  banana  phoneme  ringnorm  twonorm  phishing  \n",
       "albl         3.95     4.2      5.2       4.7     6.60       5.1  \n",
       "eer           NaN     NaN      NaN       NaN      NaN       NaN  \n",
       "kcenter      6.00     2.0      5.7       7.0     5.10       5.8  \n",
       "lal          5.70     2.4      4.8       2.8     3.10       4.0  \n",
       "margin       1.30     4.1      1.8       1.3     1.80       1.0  \n",
       "mcm          2.00     5.6      1.5       2.7     2.40       2.2  \n",
       "qbc          2.75     2.7      2.8       4.3     3.45       3.0  \n",
       "spal          NaN     NaN      NaN       NaN      NaN       NaN  \n",
       "us           6.30     7.0      6.2       5.2     5.55       6.9  \n",
       "\n",
       "[9 rows x 26 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rank_tau_qs_data = pd.DataFrame(avg_rank_tau_qs_data)\n",
    "avg_rank_tau_qs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "828b7e01-0941-4583-86a9-da52ee318afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame to LaTeX\n",
    "# largest three values in each column\n",
    "# make them as bold, bold, underline\n",
    "lbracebracket = f'{chr(123)}'\n",
    "rbracebracket = f'{chr(125)}'\n",
    "tbf = f'{chr(92)}textbf'\n",
    "tit = f'{chr(92)}textit'\n",
    "udl = f'{chr(92)}underline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae3fcf93-54c5-4974-b816-4d72a00fd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rank\n",
    "rank1_str = '\\\\textsuperscript{1}'\n",
    "rank2_str = '\\\\textsuperscript{2}'\n",
    "rank3_str = '\\\\textsuperscript{3}'\n",
    "avg_rank_tau_qs_data_latex = avg_rank_tau_qs_data.round(2).copy()\n",
    "for d in avg_rank_tau_qs_data.columns:\n",
    "    bst_q = avg_rank_tau_qs_data.loc[:, d].nsmallest(3).index\n",
    "    # export to LaTeX\n",
    "    avg_rank_tau_qs_data_latex.loc[bst_q[0], d] = f'{tbf}{lbracebracket}{avg_rank_tau_qs_data_latex.loc[bst_q[0], d]}{rbracebracket}{rank1_str}'\n",
    "    avg_rank_tau_qs_data_latex.loc[bst_q[1], d] = f'{tbf}{lbracebracket}{avg_rank_tau_qs_data_latex.loc[bst_q[1], d]}{rbracebracket}{rank2_str}'\n",
    "    avg_rank_tau_qs_data_latex.loc[bst_q[2], d] = f'{tbf}{lbracebracket}{avg_rank_tau_qs_data_latex.loc[bst_q[2], d]}{rbracebracket}{rank3_str}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2630d9be-68bb-47b1-a4b6-8cfcc9855dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add reason for undone experiments\n",
    "avg_rank_tau_qs_data_latex = avg_rank_tau_qs_data_latex.fillna('too long')\n",
    "avg_rank_tau_qs_data_latex.loc['spal', 'checkerboard'] = 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c81e3dbd-9014-4b21-815b-3fea63dd8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_tau_qs_data_latex = avg_rank_tau_qs_data_latex.T\n",
    "avg_rank_tau_qs_data_latex.columns.name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f09ddddb-1854-4117-b892-4d37f2ee7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update columns\n",
    "avg_rank_tau_qs_data_latex_str = avg_rank_tau_qs_data_latex.to_latex(\n",
    "    label='tab6:super',\n",
    "    caption='Average Ranking of the Query Startegy',\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "avg_rank_tau_qs_data_latex_str = avg_rank_tau_qs_data_latex_str.replace('{table}', '{table*}')\n",
    "with open('table6-super.tex', 'w') as f:\n",
    "    f.write(avg_rank_tau_qs_data_latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af4acef4-21a7-44ce-b293-5a98cb96c141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aubc_qs_data_seed_df = []\n",
    "for data in aubc_qs_data_seed:\n",
    "    aubc_q_d_s_ = aubc_qs_data_seed[data].copy()\n",
    "    aubc_q_d_s_ = pd.DataFrame(aubc_q_d_s_)\n",
    "    aubc_q_d_s_.columns = qs_list\n",
    "    aubc_q_d_s_ = aubc_q_d_s_.stack()\n",
    "    aubc_q_d_s_ = aubc_q_d_s_.reset_index()\n",
    "    aubc_q_d_s_['data'] = data\n",
    "    aubc_q_d_s_.columns = ['res_expno', 'qs', 'res_tst_score', 'data']\n",
    "    aubc_q_d_s_ = aubc_q_d_s_[['data', 'res_expno', 'qs', 'res_tst_score']]\n",
    "    aubc_qs_data_seed_df.append(aubc_q_d_s_)\n",
    "\n",
    "aubc_qs_data_seed_df = pd.concat(aubc_qs_data_seed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0959e88-c551-4721-91d8-c2df66bc234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aubc_qs_data_seed_view = pd.merge(left=aubc_qs_data_seed_df,\n",
    "                                  right=xz2021_table2,\n",
    "                                  how='left',\n",
    "                                  left_on='data',\n",
    "                                  right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "218868f0-5f16-4d7e-ab94-aa7b2c5f8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "aubc_RS_data_seed_view = aubc_qs_data_seed_view[aubc_qs_data_seed_view['qs']=='uniform']\n",
    "aubc_US_data_seed_view = aubc_qs_data_seed_view[aubc_qs_data_seed_view['qs']=='margin']\n",
    "\n",
    "tau_US_data_seed_view = []\n",
    "for data in data_list:\n",
    "    aubc_RS_seed_view = aubc_RS_data_seed_view[\n",
    "        aubc_RS_data_seed_view['data']==data\n",
    "    ].set_index('res_expno')\n",
    "    aubc_US_seed_view = aubc_US_data_seed_view[\n",
    "        aubc_US_data_seed_view['data']==data\n",
    "    ].set_index('res_expno')\n",
    "    tau_US_seed_view = aubc_US_seed_view['res_tst_score'] - aubc_RS_seed_view['res_tst_score']\n",
    "    tau_US_seed_view = tau_US_seed_view.to_frame()\n",
    "    tau_US_seed_view['IR'] = aubc_US_seed_view['IR']\n",
    "    tau_US_seed_view['d'] = aubc_US_seed_view['d']\n",
    "    tau_US_seed_view['n'] = aubc_US_seed_view['n']\n",
    "    tau_US_seed_view['data'] = data\n",
    "    tau_US_seed_view = tau_US_seed_view.reset_index(drop=True)\n",
    "    tau_US_data_seed_view.append(tau_US_seed_view)\n",
    "\n",
    "tau_US_data_seed_view = pd.concat(tau_US_data_seed_view)\n",
    "tau_US_data_seed_view.columns = ['margin_improve'] + tau_US_data_seed_view.columns.to_list()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca2daa41-2b92-40c6-807c-8501b3d8f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_US_data_seed_view['margin_improve'] = tau_US_data_seed_view['margin_improve'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "491c832c-6017-487d-8d98-fb75b59fa131",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.jet  # define the colormap\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmapidx = np.linspace(0, len(cmaplist)-1, len(data_list)).astype(int)\n",
    "cmapdict = {}\n",
    "for i, d in zip(cmapidx, data_list):\n",
    "    cmapdict[d] = plt.matplotlib.colors.rgb2hex(cmaplist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06496ca8-a4f5-42b8-aea0-cb7980c13649",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_US_data_seed_view['color'] = tau_US_data_seed_view['data'].map(cmapdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a489421-b198-4419-b38a-81a456c23c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "ax_tau_US_scat_mat = scatter_matrix(tau_US_data_seed_view,\n",
    "                                    alpha=0.5,\n",
    "                                    diagonal='kde',\n",
    "                                    c=tau_US_data_seed_view['color'],\n",
    "                                    s=100,\n",
    "                                    figsize=(12, 8))\n",
    "ax_tau_US_corr = tau_US_data_seed_view.corr().to_numpy()\n",
    "for i, j in zip(*plt.np.triu_indices_from(ax_tau_US_scat_mat, k=1)):\n",
    "    ax_tau_US_scat_mat[i, j].annotate(\"r=%.3f\" %ax_tau_US_corr[i, j],\n",
    "                                      (0.8, 0.8),\n",
    "                                      xycoords='axes fraction',\n",
    "                                      ha='center',\n",
    "                                      va='center')\n",
    "    ax_tau_US_scat_mat[i, j].xaxis.set_visible(True)\n",
    "    if j == 1:\n",
    "        ax_tau_US_scat_mat[i, j].yaxis.set_visible(True)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if i > 0:\n",
    "            ax_tau_US_scat_mat[i,j].set_visible(False)\n",
    "        if j == 0:\n",
    "            ax_tau_US_scat_mat[i,j].set_visible(False)\n",
    "\n",
    "plt.savefig('scatmat.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd44d4-88a8-4a4c-ae26-41e39bb5610f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al-benchmark",
   "language": "python",
   "name": "al-benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
